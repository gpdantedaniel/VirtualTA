{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucido Prototype\n",
    "This proof-of-concept runs locally for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.converters import MarkdownToDocument, PyPDFToDocument, TextFileToDocument, PPTXToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# File routing and reading\n",
    "file_type_router = FileTypeRouter(mime_types=['text/plain', 'application/pdf', 'text/markdown', 'application/vnd.openxmlformats-officedocument.presentationml.presentation'])\n",
    "text_file_converter = TextFileToDocument()\n",
    "markdown_converter = MarkdownToDocument()\n",
    "pdf_converter = PyPDFToDocument()\n",
    "powerpoint_converter = PPTXToDocument()\n",
    "\n",
    "# Document joining and pre-processing\n",
    "document_joiner = DocumentJoiner()\n",
    "document_cleaner = DocumentCleaner()\n",
    "document_splitter = DocumentSplitter(split_by='word', split_length=150, split_overlap=50)\n",
    "\n",
    "# Document embedding and writing to\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model='sentence-transformers/all-MiniLM-L6-v2')\n",
    "document_writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "# Initializing data ingestion pipeline\n",
    "ingestion_pipeline = Pipeline()\n",
    "ingestion_pipeline.add_component(instance=file_type_router, name=\"file_type_router\")\n",
    "ingestion_pipeline.add_component(instance=text_file_converter, name=\"text_file_converter\")\n",
    "ingestion_pipeline.add_component(instance=markdown_converter, name=\"markdown_converter\")\n",
    "ingestion_pipeline.add_component(instance=pdf_converter, name=\"pypdf_converter\")\n",
    "ingestion_pipeline.add_component(instance=powerpoint_converter, name='powerpoint_converter')\n",
    "ingestion_pipeline.add_component(instance=document_joiner, name=\"document_joiner\")\n",
    "ingestion_pipeline.add_component(instance=document_cleaner, name=\"document_cleaner\")\n",
    "ingestion_pipeline.add_component(instance=document_splitter, name=\"document_splitter\")\n",
    "ingestion_pipeline.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "ingestion_pipeline.add_component(instance=document_writer, name=\"document_writer\")\n",
    "\n",
    "# Connecting components\n",
    "ingestion_pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "ingestion_pipeline.connect(\"file_type_router.application/pdf\", \"pypdf_converter.sources\")\n",
    "ingestion_pipeline.connect(\"file_type_router.text/markdown\", \"markdown_converter.sources\")\n",
    "ingestion_pipeline.connect('file_type_router.application/vnd.openxmlformats-officedocument.presentationml.presentation', 'powerpoint_converter.sources')\n",
    "ingestion_pipeline.connect(\"text_file_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect(\"pypdf_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect(\"markdown_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect('powerpoint_converter', 'document_joiner')\n",
    "ingestion_pipeline.connect(\"document_joiner\", \"document_cleaner\")\n",
    "ingestion_pipeline.connect(\"document_cleaner\", \"document_splitter\")\n",
    "ingestion_pipeline.connect(\"document_splitter\", \"document_embedder\")\n",
    "ingestion_pipeline.connect(\"document_embedder\", \"document_writer\")\n",
    "\n",
    "ingestion_pipeline.draw('drawings/ingestion_pipeline.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 140 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 809 0 (offset 0)\n",
      "Ignoring wrong pointing object 811 0 (offset 0)\n",
      "Ignoring wrong pointing object 820 0 (offset 0)\n",
      "Ignoring wrong pointing object 825 0 (offset 0)\n",
      "Ignoring wrong pointing object 925 0 (offset 0)\n",
      "Ignoring wrong pointing object 931 0 (offset 0)\n",
      "Ignoring wrong pointing object 937 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 263 0 (offset 0)\n",
      "Ignoring wrong pointing object 269 0 (offset 0)\n",
      "Ignoring wrong pointing object 319 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6304632aa5014c4cb954a0c15ffcbfd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 266}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Testing the ingestion pipeline\n",
    "content_dir = 'bien210'\n",
    "ingestion_pipeline.run({'file_type_router': {'sources': list(Path(content_dir).glob(\"**/*\"))}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG Chat Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "template = [ChatMessage.from_system(\"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\")]\n",
    "\n",
    "# Initializing the RAG pipeline\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "rag_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store, top_k=5))\n",
    "rag_pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(template=template))\n",
    "\n",
    "# Connecting the components\n",
    "rag_pipeline.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "\n",
    "rag_pipeline.draw('drawings/rag_pipeline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a2f49348bd4f80a8c76d1fc69474cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnswer the questions based on the given context.\\n\\nContext:\\n\\n    axon. Myelinated neurons transmit information at least one order of magnitude faster than unmyelinated neurons. Schwann cells are responsible for myelination. They add myelin at just the right locations along the axon to allow sodium channels to open at specific nodes, called Nodes of Ranvier. This allows for an action potential to move in a very targeted way, from node to node. Propagation of the signal like this is called saltatory conduction (meaning “jumping conduction”) . 4. Describe the role of synapses and connexons At the end of a neuron, the action potential must be communicated to the following neuron.\\x0c32 This is done through synapses and connexons. ◆ Synapses use neurotransmitters to transmit the action potential. This is a form of chemical communication. Synapses are useful because they prevent signals from traveling backwards (there are no receptors for the neurotransmitters at the end of the neuron) and because the signal \\n\\n    neuron cannot fire another action potential. This period is known as the refractory period. 5) Finally, the membrane returns to its resting potential of -70 millivolts. It is interesting to note that while the depolarization of the membrane is bidirectional, propagation of the action potential is unidirectional. In fact, the refractory period of the previous neuron prevents the action potential from going backwards: sodium channels cannot be activated during this period. As such, only subsequent sodium channels can be activated! The speed of propagation of the signal along nerves depends heavily on myelination (the addition of myelin) of the neuron’s axon. Myelinated neurons transmit information at least one order of magnitude faster than unmyelinated neurons. Schwann cells are responsible for myelination. They add myelin at just the right locations along the axon to allow sodium channels to open at specific nodes, called Nodes of Ranvier. This allows for an action \\n\\n    proteins in the membrane. Each channel has its own function: ◆ Resting potassium channels generate the resting potential across the membrane. ◆ Voltage-gated channels propagate the action potential. As their name suggests, a certain voltage is needed to activate them. ◆ Ligand-gated and signal-gated channels, present in dendrites and neuronal cell bodies generate electric signals in post-synaptic cells. • Ligand-gated channels have a site for a particular extracellular neurotransmitter to bind. This means they respond to external stimuli. • Signal-gated channels respond to intracellular signals resulting from a neurotransmitter binding to a distant receptor. Overall, a neurotransmitter binds to a receptor, which activates a G protein (a protein used in signal transduction within cells). This G protein travels to the signal-gated channel, activating it. When a large enough signal is received by a neuron, the membrane begins to depolarize as a result of voltage-gated channels’ activation. The resting potential is \\n\\n    This is done through synapses and connexons. ◆ Synapses use neurotransmitters to transmit the action potential. This is a form of chemical communication. Synapses are useful because they prevent signals from traveling backwards (there are no receptors for the neurotransmitters at the end of the neuron) and because the signal is completely regenerated to full strength (signal amplification) after being passed on to the next neuron. The signal is transmitted as follows: 1) The action potential arrives at the synapse and causes calcium-releasing voltage-gated channels to open. Calcium triggers neurotransmitter vesicle fusion with the membrane. 2) Neurotransmitters are released into the synapse. 3) Neurotransmitters diffuse across the synapse. 4) Receptors on the accepting (“post-synaptic”) neuron bind the neurotransmitters. 5) The post-synaptic neuron’s membrane depolarizes, propagating the action potential. ◆ Connexons use electric impulses to transmit information. This is instead a form of electrical communication. Connexons do not require the relatively \\n\\n    Artificial-leaf: https://www.zmescience.com/ecology/green-living/silk-leaf-first-biological-leaf-055343/ • Nitrogen-fixation: https://socratic.org/questions/how-can-nitrogen-be-fixed-naturally-for-plant-use • Gated Channel: https://www.news-medical.net/health/Importance-of-Ion-Channels-in-the-Body.aspx • Schwann: https://www.getbodysmart.com/neuron-support-cells/schwann-cells • Connexon: https://www.nature.com/articles/nrm1072 • Cantilever: https://dailycivil.com/cantilever-beam-advantages-disadvantages/ • Photodiode: https://instrumentationtools.com/photodiode-working-principle/ • Griffith: https://en.wikipedia.org/wiki/Griffith%27s_experiment • Restriction-enzyme: https://www.khanacademy.org/science/biology/biotech-dna-technology/dna-cloning-tutorial/a/restriction-enzymes-dna-ligase\\x0c• LAC: https://www.khanacademy.org/science/ap-biology/gene-expression-and-regulation/regulation-of-gene-expression-and-cell-specialization/a/the-lac-operon • GFP: https://resources.chromotek.com/blog/green-fluorescent-proteins-tools • Sanger Sequencing: https://letstalkscience.ca/educational-resources/backgrounders/sanger-sequencing • Crispr: https://en.wikipedia.org/wiki/CRISPR_gene_editing • Intermolecular Bonds: https://isaacscienceblog.com/2016/11/05/intermolecular-forces/ • Coffee Ring Effect: https://www.researchgate.net/figure/Flow-towards-droplet-edges-can-result-in-the-coffee-ring-effect-CRE-Dotted-arrows-show_fig2_323373350 • Interactome: https://www.researchgate.net/figure/nteractome-analysis-reveals-known-and-novel-interactions-for-A20-Affinity-purification_fig3_328356932 • Gecko: https://www.sciencephoto.com/media/379141/view/gecko-foot-hairs-sem • Optofluidics: https://blogs.rsc.org/lc/2018/01/17/why-should-we-use-optofluidics-for-monitoring-marine-environment/ • Transistor: https://learn.sparkfun.com/tutorials/transistors/all • DMD: https://www.spiedigitallibrary.org/journals/Journal-of-Astronomical-Telescopes-Instruments-and-Systems/volume-3/issue-3/035003/Evaluation-of-digital-micromirror-devices-for-use-in-space-based/10.1117/1.JATIS.3.3.035003.short?SSO=1 • Retrovirus: https://en.wikipedia.org/wiki/Retrovirus • Biosensor: https://www.mdpi.com/2079-6374/8/2/29/htm • PCR: https://perlong.en.made-in-china.com/product/njaxhkLAOHVv/China-Ce-Improved-PCR-Machine-Thermal-Cycler-for-DNA-Testing-Machine-High-Quality.html\\n\\nQuestion: What do Schwann cells do in Myelination?\\nAnswer:'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the rag chat pipeline\n",
    "query = 'What do Schwann cells do in Myelination?'\n",
    "result = rag_pipeline.run({\n",
    "  'embedder': {'text': query}, \n",
    "  'prompt_builder': {'question': query}\n",
    "})\n",
    "\n",
    "result['prompt_builder']['prompt'][0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradio Chatbot Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API token:\")\n",
    "\n",
    "messages = [ChatMessage.from_system(\"You are a virtual teaching assistant. Answer questions based on the given context\")]\n",
    "chat_generator = OpenAIChatGenerator(model='gpt-3.5-turbo')\n",
    "\n",
    "def chatbot(query:str, history) -> str:\n",
    "  # Generate the RAG prompt \n",
    "  rag_response = rag_pipeline.run({'embedder': {'text': query}, 'prompt_builder': {'question': query}})\n",
    "  rag_prompt = rag_response['prompt_builder']['prompt'][0].content\n",
    "  messages.append(ChatMessage.from_user(rag_prompt))\n",
    "\n",
    "  # Generate the LLM response\n",
    "  llm_response = chat_generator.run(messages=messages)\n",
    "  reply = llm_response['replies'][0]\n",
    "  messages.append(reply)\n",
    "\n",
    "  return reply.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chatbot function\n",
    "# chatbot(\"What is electric skin?\", _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\components\\chatbot.py:248: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cb4a57d11b48df892d2c772dddba91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca512401d95540629b305e09e5d11b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec6909d2fa04da3ba118601ef378f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15ab5a1c50c41eb90843ffbc77b0a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef4b9210aa149d697679794d3137445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2058c7197c470088ec191f036d5d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e1bcc12d7f49b191381c142e6a281c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d2e475aa3441219b721827eab6c011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4516321337c144be88db0cbf338c6701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9625210f0d4c27b64af97ed6630bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fff029b439b49b3beff0e6dee12db30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f30d5b94af4e1faf8edee28c678a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6cd1805e334dcea6f5d14c0d3b13bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878a8a6c73454a9484a2d3fa4d22c9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1592, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\utils.py\", line 836, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 618, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2505, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1005, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dante\\AppData\\Local\\Temp\\ipykernel_16968\\2739067027.py\", line 16, in chatbot\n",
      "    llm_response = chat_generator.run(messages=messages)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\haystack\\components\\generators\\chat\\openai.py\", line 211, in run\n",
      "    chat_completion: Union[Stream[ChatCompletionChunk], ChatCompletion] = self.client.chat.completions.create(\n",
      "                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 859, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 17667 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "demo = gr.ChatInterface(fn=chatbot, title=\"Lucido — A BIEN 210 Application\",)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
