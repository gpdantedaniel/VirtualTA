{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucido Prototype\n",
    "This proof-of-concept runs locally for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.converters import MarkdownToDocument, PyPDFToDocument, TextFileToDocument, PPTXToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# File routing and reading\n",
    "text_file_converter = TextFileToDocument()\n",
    "markdown_converter = MarkdownToDocument()\n",
    "pdf_converter = PyPDFToDocument()\n",
    "powerpoint_converter = PPTXToDocument()\n",
    "file_type_router = FileTypeRouter(mime_types=[\n",
    "    'text/plain', \n",
    "    'application/pdf', \n",
    "    'text/markdown', \n",
    "    'application/vnd.openxmlformats-officedocument.presentationml.presentation'\n",
    "])\n",
    "\n",
    "# Document joining and pre-processing\n",
    "document_joiner = DocumentJoiner()\n",
    "document_cleaner = DocumentCleaner()\n",
    "document_splitter = DocumentSplitter(split_by='word', split_length=150, split_overlap=50)\n",
    "\n",
    "# Document embedding and writing to\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model='sentence-transformers/all-MiniLM-L6-v2')\n",
    "document_writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "# Initializing data ingestion pipeline\n",
    "ingestion_pipeline = Pipeline()\n",
    "ingestion_pipeline.add_component(instance=file_type_router, name=\"file_type_router\")\n",
    "ingestion_pipeline.add_component(instance=text_file_converter, name=\"text_file_converter\")\n",
    "ingestion_pipeline.add_component(instance=markdown_converter, name=\"markdown_converter\")\n",
    "ingestion_pipeline.add_component(instance=pdf_converter, name=\"pypdf_converter\")\n",
    "ingestion_pipeline.add_component(instance=powerpoint_converter, name='powerpoint_converter')\n",
    "ingestion_pipeline.add_component(instance=document_joiner, name=\"document_joiner\")\n",
    "ingestion_pipeline.add_component(instance=document_cleaner, name=\"document_cleaner\")\n",
    "ingestion_pipeline.add_component(instance=document_splitter, name=\"document_splitter\")\n",
    "ingestion_pipeline.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "ingestion_pipeline.add_component(instance=document_writer, name=\"document_writer\")\n",
    "\n",
    "# Connecting components\n",
    "ingestion_pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "ingestion_pipeline.connect(\"file_type_router.application/pdf\", \"pypdf_converter.sources\")\n",
    "ingestion_pipeline.connect(\"file_type_router.text/markdown\", \"markdown_converter.sources\")\n",
    "ingestion_pipeline.connect('file_type_router.application/vnd.openxmlformats-officedocument.presentationml.presentation', 'powerpoint_converter.sources')\n",
    "ingestion_pipeline.connect(\"text_file_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect(\"pypdf_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect(\"markdown_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect('powerpoint_converter', 'document_joiner')\n",
    "ingestion_pipeline.connect(\"document_joiner\", \"document_cleaner\")\n",
    "ingestion_pipeline.connect(\"document_cleaner\", \"document_splitter\")\n",
    "ingestion_pipeline.connect(\"document_splitter\", \"document_embedder\")\n",
    "ingestion_pipeline.connect(\"document_embedder\", \"document_writer\")\n",
    "\n",
    "ingestion_pipeline.draw('drawings/ingestion_pipeline.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 140 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 809 0 (offset 0)\n",
      "Ignoring wrong pointing object 811 0 (offset 0)\n",
      "Ignoring wrong pointing object 820 0 (offset 0)\n",
      "Ignoring wrong pointing object 825 0 (offset 0)\n",
      "Ignoring wrong pointing object 925 0 (offset 0)\n",
      "Ignoring wrong pointing object 931 0 (offset 0)\n",
      "Ignoring wrong pointing object 937 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 263 0 (offset 0)\n",
      "Ignoring wrong pointing object 269 0 (offset 0)\n",
      "Ignoring wrong pointing object 319 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7408b3f2d5024c639be19158d5243885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 266}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Testing the ingestion pipeline\n",
    "content_dir = 'bien210'\n",
    "ingestion_pipeline.run({'file_type_router': {'sources': list(Path(content_dir).glob(\"**/*\"))}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever, InMemoryBM25Retriever\n",
    "from haystack.components.rankers import TransformersSimilarityRanker\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators.hugging_face_api import HuggingFaceAPIGenerator\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the given context. Be brief.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize embedder and store retrievers\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embedding_retriever = InMemoryEmbeddingRetriever(document_store=document_store)\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store=document_store)\n",
    "\n",
    "# Initialize document joiner and ranker\n",
    "document_joiner = DocumentJoiner()\n",
    "ranker = TransformersSimilarityRanker(\n",
    "  model='BAAI/bge-reranker-base'\n",
    ")\n",
    "\n",
    "# Initialize LLM generation components\n",
    "prompt_builder = PromptBuilder(template=template)\n",
    "llm = HuggingFaceAPIGenerator(\n",
    "  api_type=\"serverless_inference_api\",\n",
    "  api_params={\"model\": \"HuggingFaceH4/zephyr-7b-beta\"},\n",
    "  generation_kwargs={'max_new_tokens': 150}\n",
    ")\n",
    "\n",
    "# Initialize the RAG pipeline\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "rag_pipeline.add_component(\"embedding_retriever\", embedding_retriever)\n",
    "rag_pipeline.add_component('bm25_retriever', bm25_retriever)\n",
    "rag_pipeline.add_component('document_joiner', document_joiner)\n",
    "rag_pipeline.add_component('ranker', ranker)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component('llm', llm)\n",
    "\n",
    "# Connecting the components\n",
    "rag_pipeline.connect('text_embedder', 'embedding_retriever')\n",
    "rag_pipeline.connect('embedding_retriever', 'document_joiner')\n",
    "rag_pipeline.connect('bm25_retriever', 'document_joiner')\n",
    "rag_pipeline.connect('document_joiner', 'ranker')\n",
    "rag_pipeline.connect(\"ranker.documents\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect('prompt_builder', 'llm')\n",
    "\n",
    "rag_pipeline.draw('drawings/rag_pipeline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2444c3a29f9489c8de1763947d58092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:2245: FutureWarning: `stop_sequences` is a deprecated argument for `text_generation` task and will be removed in version '0.28.0'. Use `stop` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Test the RAG pipeline\n",
    "question = 'How does myelination of the axons help increase signal speeds in neurons?'\n",
    "result = rag_pipeline.run({\n",
    "  'text_embedder': {'text': question},\n",
    "  'bm25_retriever': {'query': question},\n",
    "  'ranker': {'query': question},\n",
    "  'prompt_builder': {'question': question}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Myelinated neurons transmit information at least one order of magnitude faster than unmyelinated neurons due to saltatory conduction, which allows for an action potential to move in a very targeted way, from node to node, as a result of myelin being added at just the right locations along the axon to allow sodium channels to open at specific nodes called Nodes of Ranvier. This allows for an action potential to move quickly and efficiently along the axon, as opposed to unmyelinated neurons, where the action potential must travel more slowly due to the lack of myelin and the need for the signal to regenerate at each point along the axon.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['llm']['replies'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradio Chatbot Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.generators.chat import HuggingFaceAPIChatGenerator\n",
    "from haystack.dataclasses import ChatMessage\n",
    "\n",
    "if \"HF_API_TOKEN\" not in os.environ:\n",
    "    os.environ[\"HF_API_TOKEN\"] = getpass(\"Enter HuggingFace API token:\")\n",
    "\n",
    "messages = [ChatMessage.from_system(\"\"\"\n",
    "You are Lucido, a helpful teaching assistant. Answer questions based on hints provided to you by the system. \n",
    "If the hints are insufficient, inform the user that you do not have the knowledge to answer that question.\n",
    "\"\"\")]\n",
    "\n",
    "chat_generator = HuggingFaceAPIChatGenerator(\n",
    "  api_type=\"serverless_inference_api\",\n",
    "  api_params={\"model\": \"HuggingFaceH4/zephyr-7b-beta\"},\n",
    "  # generation_kwargs={'max_tokens': 150}\n",
    ")\n",
    "\n",
    "def chatbot(query, _):\n",
    "  # Generate the RAG response \n",
    "  rag_response = rag_pipeline.run({\n",
    "    'text_embedder': {'text': query},\n",
    "    'bm25_retriever': {'query': query},\n",
    "    'ranker': {'query': query},\n",
    "    'prompt_builder': {'question': query}\n",
    "  })\n",
    "  \n",
    "  rag_reply = rag_response['llm']['replies'][0]\n",
    "  messages.append(ChatMessage.from_system(rag_reply))\n",
    "  messages.append(ChatMessage.from_user(query))\n",
    "  result = chat_generator.run(messages=messages)\n",
    "  reply = result['replies'][0].content\n",
    "\n",
    "  return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\VirtualTA\\venv\\Lib\\site-packages\\gradio\\components\\chatbot.py:248: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def upload_file(filepath):\n",
    "  print(filepath)\n",
    "  ingestion_pipeline.run({'file_type_router': {'sources': [Path(filepath)]}})\n",
    "\n",
    "with gr.Blocks() as demo: \n",
    "  gr.ChatInterface(\n",
    "    fn=chatbot, \n",
    "    title=\"Lucido — A BIEN 210 Application\",\n",
    "    examples=[\n",
    "      'How does myelination of the axons help increase signal speeds in neurons?',\n",
    "      'How does bioluminescence differ from chemiluminescence?',\n",
    "      'Why can the cell membrane be compared to a PN-junction?',\n",
    "      'How could artificial leaves help society and how do they compare to photosynthesis?',\n",
    "      'What are the two main superhydrophobic regimes and how can they be applied?',\n",
    "      'What is a lateral flow assay, how is it built, and what are its uses?'\n",
    "    ]\n",
    "  )\n",
    "  \n",
    "  upload_button = gr.UploadButton('Upload a file', file_count='single', variant='primary')\n",
    "  upload_button.upload(upload_file, upload_button)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
