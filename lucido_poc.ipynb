{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lucido Prototype\n",
    "This proof-of-concept runs locally for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.converters import MarkdownToDocument, PyPDFToDocument, TextFileToDocument, PPTXToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "# File routing and reading\n",
    "file_type_router = FileTypeRouter(mime_types=['text/plain', 'application/pdf', 'text/markdown', 'application/vnd.openxmlformats-officedocument.presentationml.presentation'])\n",
    "text_file_converter = TextFileToDocument()\n",
    "markdown_converter = MarkdownToDocument()\n",
    "pdf_converter = PyPDFToDocument()\n",
    "powerpoint_converter = PPTXToDocument()\n",
    "\n",
    "# Document joining and pre-processing\n",
    "document_joiner = DocumentJoiner()\n",
    "document_cleaner = DocumentCleaner()\n",
    "document_splitter = DocumentSplitter(split_by='word', split_length=150, split_overlap=50)\n",
    "\n",
    "# Document embedding and writing to\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model='sentence-transformers/all-MiniLM-L6-v2')\n",
    "document_writer = DocumentWriter(document_store=document_store)\n",
    "\n",
    "# Initializing data ingestion pipeline\n",
    "ingestion_pipeline = Pipeline()\n",
    "ingestion_pipeline.add_component(instance=file_type_router, name=\"file_type_router\")\n",
    "ingestion_pipeline.add_component(instance=text_file_converter, name=\"text_file_converter\")\n",
    "ingestion_pipeline.add_component(instance=markdown_converter, name=\"markdown_converter\")\n",
    "ingestion_pipeline.add_component(instance=pdf_converter, name=\"pypdf_converter\")\n",
    "ingestion_pipeline.add_component(instance=powerpoint_converter, name='powerpoint_converter')\n",
    "ingestion_pipeline.add_component(instance=document_joiner, name=\"document_joiner\")\n",
    "ingestion_pipeline.add_component(instance=document_cleaner, name=\"document_cleaner\")\n",
    "ingestion_pipeline.add_component(instance=document_splitter, name=\"document_splitter\")\n",
    "ingestion_pipeline.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "ingestion_pipeline.add_component(instance=document_writer, name=\"document_writer\")\n",
    "\n",
    "# Connecting components\n",
    "ingestion_pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "ingestion_pipeline.connect(\"file_type_router.application/pdf\", \"pypdf_converter.sources\")\n",
    "ingestion_pipeline.connect(\"file_type_router.text/markdown\", \"markdown_converter.sources\")\n",
    "ingestion_pipeline.connect('file_type_router.application/vnd.openxmlformats-officedocument.presentationml.presentation', 'powerpoint_converter.sources')\n",
    "ingestion_pipeline.connect(\"text_file_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect(\"pypdf_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect(\"markdown_converter\", \"document_joiner\")\n",
    "ingestion_pipeline.connect('powerpoint_converter', 'document_joiner')\n",
    "ingestion_pipeline.connect(\"document_joiner\", \"document_cleaner\")\n",
    "ingestion_pipeline.connect(\"document_cleaner\", \"document_splitter\")\n",
    "ingestion_pipeline.connect(\"document_splitter\", \"document_embedder\")\n",
    "ingestion_pipeline.connect(\"document_embedder\", \"document_writer\")\n",
    "\n",
    "ingestion_pipeline.draw('drawings/ingestion_pipeline.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 134 0 (offset 0)\n",
      "Ignoring wrong pointing object 140 0 (offset 0)\n",
      "Ignoring wrong pointing object 146 0 (offset 0)\n",
      "Ignoring wrong pointing object 809 0 (offset 0)\n",
      "Ignoring wrong pointing object 811 0 (offset 0)\n",
      "Ignoring wrong pointing object 820 0 (offset 0)\n",
      "Ignoring wrong pointing object 825 0 (offset 0)\n",
      "Ignoring wrong pointing object 925 0 (offset 0)\n",
      "Ignoring wrong pointing object 931 0 (offset 0)\n",
      "Ignoring wrong pointing object 937 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 263 0 (offset 0)\n",
      "Ignoring wrong pointing object 269 0 (offset 0)\n",
      "Ignoring wrong pointing object 319 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3345aea11ed241f3ad6f53f9fca86ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 42}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "content_dir = 'bien210'\n",
    "\n",
    "# Testing the ingestion pipeline\n",
    "ingestion_pipeline.run({\n",
    "  'file_type_router': {\n",
    "    'sources': list(Path(content_dir).glob(\"**/*\"))\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API token:\")\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "llm_geneartor = OpenAIGenerator(model='gpt-3.5-turbo')\n",
    "\n",
    "# Initializing the RAG pipeline\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "rag_pipeline.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "rag_pipeline.add_component(\"llm\", llm_geneartor)\n",
    "\n",
    "# Connecting the components\n",
    "rag_pipeline.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "rag_pipeline.draw('drawings/rag_pipeline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740f8770a7474e68936c91d055dd5413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Electronic skin finds applications in healthcare, robotics, prosthetics, tele-operated robotic surgery, and object recognition.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9bd9396d2946c2b71eb57f68b48058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = (\n",
    "  'In what domains does electric skin find applications?'\n",
    ")\n",
    "\n",
    "result = rag_pipeline.run(\n",
    "  {\n",
    "    'embedder': {'text': question},\n",
    "    'prompt_builder': {'question': question},\n",
    "  }\n",
    ")\n",
    "\n",
    "result['llm']['replies'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695b7bcad2f546c681a45b7454cee33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4914f385dac4b14a4a41e3ad66e1070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def query_rag(query):\n",
    "  result = rag_pipeline.run({\n",
    "    'embedder': {'text': query},\n",
    "    'prompt_builder': {'question': query}\n",
    "  })\n",
    "  return result['llm']['replies'][0]\n",
    "\n",
    "demo = gr.Interface(\n",
    "  fn=query_rag,\n",
    "  inputs=['text'],\n",
    "  outputs=['text']\n",
    ")\n",
    "\n",
    "demo.launch()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
